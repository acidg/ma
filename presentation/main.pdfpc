[duration]
20
[font_size]
21
[notes]
### 1
- Halbes Jahr 
- Entwicklung Werkzeug open source Lizenzverstößen aufdecken 
- "Open source" verbindet man Wiederverwendung 
- Lizenzverletzungen!  
### 2
- Viele Open Source Lizenzen, kleiner Ausschnitt der Bekannteren 
- anpassbar, selbst entwickeln -> Kompliziert , darf ich kopieren?
- JSON-License: "The Software shall be used for Good, not Evil" 
- Unwissenheit: darf ich kopieren? Ignoranz 
- Tool: aufdecken von open source lizenzverletzungen  
### 3
 AUFBAU PRÄSENTATION: 
- Andere Arbeiten 
- Daraus folgernd: Ansatz 
- Analyse Performanz, test: kann Lizenzverletzungen aufdecken? 
- Abschließend geb ich kurzes Fazit  
### 4
- Ältestes relevantes forschungsgebiet: Plagiatsoftware Abgaben von Studenten Programmierkurse\\
-> kaum skalierbar, anderer kontext: Programm vorgegeben
- Clone detection, software qualität, zwei ansätze: abstract syntax tree vs index
- Search engines: Verwalten rießige Mengen Quellcode, Struktursuche, multilevel index
- Kommerziele Programme, lizenzprobleme aufdecken: Kaum Details, Vertraulichkeit des Sourcecodes
- (Kontinuierliche) mehrfache analyse, einfache skalierbarkeit -> index = Key-value store### 5
- Statt index auf jeder maschine: client-server

- Auf server: Pool an repositories von open source projekten 
- baut index auf 
- überwacht Änderungen und updatet entsprechend### 6
- Entfernt Formattierung, comments, access modifiers, brackets, import statements, keywords wie final/static 
- Übriges: "Fingerabdruck" (Struktur, Variablennamen, Literale, ...)  
- code leichter vergleichbar### 7
- Normalisierter code in statements aufgeteilt 
- Sliding windows: in "chunks" gruppiert 
- 5 statements = 1 chunk 
- Chunks hashen 
- Position chunk (projekt, path der datei innerhalb, start und ende) in index speichern 
- Index ist key value store, hash = key,  
### 8
- Code aus alter version finden, alte version indexieren 
- Jeder commit sehr hoher Aufwand
- Git Tags als referenzpunkte 
- Dateien, die von einer zur nächsten version verändert, neu indexiert  
### 9
- Suche auf client ähnlich wie indexierung auf server 
- normalisiert code, chunks gruppieren, hashen 
- mit Index abgleichen  
### 10
- Viele chunks -> viele requests -> Dauert, last auf server hoch 

- Datenstruktur, auf server mithilfe von index generiert
- Größe nur Bruchteil von index
- Client kann entscheiden ob hash teil von index 
- Fehlerbehaftet: hash doch kein teil von index -> filtern auf server 
- Fehler auch sehr klein: in prototyp 0,01\% 
- requests reduzieren: weil nur details für treffer laden  ### 11
- gesamte architektur 
- Download hash filter 
- client filtert hashes, rest am server abgefragt
- server antwortet: positionen von treffern  
- treffer aggregieren und filtern
- anzahl treffer in datei lässt wahrscheinlichkeit für verletzung abschätzen### 12
- Ziel: Performanz des Ansatzes testen und Brauchbarkeit der Ergebnisse untersuchen  
### 13
- GPL projekte von github geladen + indexiert 
- Fast halbe Mrd relevante Zeilen (java oder c bzw c++) 
- Java mehr bilder, binaries, und andere resourcen -> weniger locs, auch historie kürzer, jüngere projekte 
- 15h, 37GB Indexdaten, 200 MB filter 
- Update: nach 2 wochen dauer 1h ca 1/3 der Projekte neue tags  
### 14
- Gegentest: 10 und 10 projekte java, c/c++ rausgesucht, treffer kategorisiert
- Diesmal Apache, MIT, closed
- Wichtig: GPL nicht drin erlaubt
- Keine libraries, damit weniger richtung gpl kopiert
### 15
- Treffer durch interf. impl (listen, equals methoden, api structs...) 
- kategorisieren: Lizenz rausfinden schwierig, unklar ob verletzung (header fehlt, keine anmerkungen in kommentaren)
-> apache/MIT zu GPL, oft auch nicht richtig vermerkt (teamscale blog), forks

- bloom (~1%): reduzierte last auf server 
- in 25%: JDK kopiert/quelle nicht vermerkt  
### 16
- Lizenz Projekt vs Lizenz Dateien -> verschiedene Bedingungen für kopie
- Prozess automatisieren sehr schwierig, manuell zeitaufwändig 
- nötig, enscheiden wie gravierend verletzung (abhängig von wichtigkeit des codes)

- Möglich kleine kopien finden, bloom beschleunigt suche, reduziert Last 
- Skalierbar bei indexierung und suche 
- Verwalten von externem code, Sicherheitslücken aufdecken